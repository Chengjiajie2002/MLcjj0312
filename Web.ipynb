{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b37682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from user_agents import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdffc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集数据并合并，此时数据格式为DataFrame\n",
    "train=pd.concat([\n",
    "    pd.read_csv('./data/train/SQL注入.csv'),\n",
    "    pd.read_csv('./data/train/XSS跨站脚本.csv'),\n",
    "    pd.read_csv('./data/train/命令执行.csv'),\n",
    "    pd.read_csv('./data/train/白.csv'),\n",
    "    pd.read_csv('./data/train/目录遍历.csv'),\n",
    "    pd.read_csv('./data/train/远程代码执行.csv'),\n",
    "],axis=0).reset_index(drop=True)\n",
    "train=train.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7e7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试集数据，此时数据格式为DataFrame\n",
    "test=pd.read_csv('./data/test/test.csv')\n",
    "test=test.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并训练集、测试集,并重置index\n",
    "data=pd.concat([train,test],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196d032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空值处理，用NaN去填充空值\n",
    "data=data.fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac949cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent解析\n",
    "agent_cols=['browser_family', 'os_family', 'device_family','device_brand','device_model']\n",
    "\n",
    "\n",
    "def get_ua(a):\n",
    "    user_agent = parse(a['user_agent'])\n",
    "    browser_family=str(user_agent.browser.family)\n",
    "    os_family=str(user_agent.os.family)\n",
    "    device_family=str(user_agent.device.family)\n",
    "    device_brand=str(user_agent.device.brand)\n",
    "    device_model=str(user_agent.device.model)\n",
    "    return browser_family,os_family,device_family,device_brand,device_model\n",
    "\n",
    "\n",
    "data[agent_cols] = data.apply(get_ua, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f285570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer 文本向量化\n",
    "texts=data['user_agent'].values.tolist()\n",
    "n_components = 16\n",
    "tf = TfidfVectorizer(min_df= 3, max_df=0.5,analyzer = 'char_wb', ngram_range = (2,5))  #计算tf-idf\n",
    "X = tf.fit_transform(texts)  # 得到tf-idf矩阵，稀疏矩阵表示法\n",
    "svd = TruncatedSVD(n_components=n_components,random_state=42)  # 数据降维，计算矩阵的前n_components个奇异值和向量\n",
    "X_svd = svd.fit_transform(X)   # 得到tf-idf矩阵的前16个奇异值和向量\n",
    "df_tfidf = pd.DataFrame(X_svd)\n",
    "df_tfidf.columns = [f'user_agent_name_tfidf_{i}' for i in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3fce778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data,df_tfidf],axis=1)  # 在列方向，合并data和df_tfidf\n",
    "cate_cols=['method','user_agent','url','refer','body'] + agent_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ae35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对不连续的数字或者文本进行编号\n",
    "for col in cate_cols:\n",
    "    lbl = LabelEncoder()    # 对数据集进行编码\n",
    "    lbl.fit(data[col])    # 计算出唯一的值并为其赋值\n",
    "    data[col] = lbl.transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882330c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data[:len(train)], data[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "204b1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排除特征\n",
    "feature_names = list(\n",
    "    filter(lambda x: x not in ['id','lable','url'],train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4624efc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13182\\AppData\\Local\\Temp\\ipykernel_14692\\3714718029.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['lable']=train['lable'].apply(lambda i:int(i))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 5, 4, 0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label转为int类型\n",
    "train['lable']=train['lable'].apply(lambda i:int(i))\n",
    "train['lable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "563dc141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k折交叉验证划分训练集，LightGBM建模\n",
    "def lgb_model(train, target, test, k):\n",
    "    feats = [f for f in train.columns if f not in ['lable',  'url']]\n",
    "\n",
    "    print('Current num of features:', len(feats))\n",
    "\n",
    "    oof_probs = np.zeros((train.shape[0],6))\n",
    "    output_preds = 0\n",
    "    score = []\n",
    "    \n",
    "    # LightGBM参数设置\n",
    "    parameters = {\n",
    "        'learning_rate': 0.05,       # 学习率\n",
    "        'boosting_type': 'gbdt',     # 提升类型为传统的梯度提升决策树\n",
    "        'objective': 'multiclass',   # 学习目标为softmax的目标函数\n",
    "        'metric': 'multi_error',     # 评估函数为出错率分类\n",
    "        'num_class': 6,              # 类别数量\n",
    "        'num_leaves': 31,            # 每棵树的叶子数\n",
    "        'feature_fraction': 0.6,     # 特征抽取比例\n",
    "        'bagging_fraction': 0.8,     # 样本采样比例\n",
    "        'min_data_in_leaf': 15,      # 一个叶子上数据的最小数量，可以用来处理过拟合\n",
    "        'verbose': -1,               # 冗长警告\n",
    "        'nthread': 4,                # LightGBM的线程数\n",
    "        'max_depth': 7               # 树的深度\n",
    "    }\n",
    "\n",
    "    # k折交叉验证\n",
    "    folds = StratifiedKFold(n_splits = k,                 # 折叠次数，默认为3，至少为2\n",
    "                            shuffle = True,              # 是否在每次分割之前打乱顺序\n",
    "                            random_state = 2022          # 随机种子，在shuffle==True时使用，默认使用np.random。\n",
    "                           )\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "        train_X = train[feats].iloc[train_index, :]\n",
    "        train_Y = target.iloc[train_index]\n",
    "        test_X = train[feats].iloc[test_index, :]\n",
    "        test_Y = target.iloc[test_index]\n",
    "        dtrain = lgb.Dataset(train_X,label=train_Y)\n",
    "        dval = lgb.Dataset(test_X,label=test_Y)\n",
    "        # 采用LightGBM训练模型\n",
    "        lgb_model = lgb.train(\n",
    "            parameters,\n",
    "            dtrain,\n",
    "            num_boost_round = 10000,\n",
    "            valid_sets = [dval],\n",
    "            callbacks = [early_stopping(100), log_evaluation(100)]\n",
    "        )\n",
    "        oof_probs[test_index] = lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration) \n",
    "        score.append(lgb_model.best_score['valid_0']['multi_error'])\n",
    "        output_preds += lgb_model.predict(test[feats],num_iteration=lgb_model.best_iteration) / folds.n_splits \n",
    "        print(offline_score)\n",
    "            \n",
    "    return output_preds, oof_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95a8483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练模型BEGIN\n",
      "Current num of features: 25\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.105057\n",
      "[200]\tvalid_0's multi_error: 0.0972306\n",
      "[300]\tvalid_0's multi_error: 0.0978326\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_error: 0.0960265\n",
      "[0.09602649006622517]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.10897\n",
      "[200]\tvalid_0's multi_error: 0.105057\n",
      "[300]\tvalid_0's multi_error: 0.102348\n",
      "[400]\tvalid_0's multi_error: 0.103552\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's multi_error: 0.101746\n",
      "[0.09602649006622517, 0.10174593618302227]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.10295\n",
      "[200]\tvalid_0's multi_error: 0.0972306\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_error: 0.0972306\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.0981337\n",
      "[200]\tvalid_0's multi_error: 0.0939193\n",
      "[300]\tvalid_0's multi_error: 0.0939193\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's multi_error: 0.0921132\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087, 0.09211318482841661]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.0930163\n",
      "[200]\tvalid_0's multi_error: 0.089705\n",
      "[300]\tvalid_0's multi_error: 0.0872968\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's multi_error: 0.0869958\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087, 0.09211318482841661, 0.08699578567128236]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.102649\n",
      "[200]\tvalid_0's multi_error: 0.0966285\n",
      "[300]\tvalid_0's multi_error: 0.0924142\n",
      "[400]\tvalid_0's multi_error: 0.0921132\n",
      "[500]\tvalid_0's multi_error: 0.0915111\n",
      "Early stopping, best iteration is:\n",
      "[446]\tvalid_0's multi_error: 0.0906081\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087, 0.09211318482841661, 0.08699578567128236, 0.09060806742925948]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.0936183\n",
      "[200]\tvalid_0's multi_error: 0.0881999\n",
      "[300]\tvalid_0's multi_error: 0.0872968\n",
      "[400]\tvalid_0's multi_error: 0.0857917\n",
      "[500]\tvalid_0's multi_error: 0.0854907\n",
      "Early stopping, best iteration is:\n",
      "[463]\tvalid_0's multi_error: 0.0851896\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087, 0.09211318482841661, 0.08699578567128236, 0.09060806742925948, 0.0851896447922938]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.101746\n",
      "[200]\tvalid_0's multi_error: 0.0999398\n",
      "[300]\tvalid_0's multi_error: 0.0981337\n",
      "[400]\tvalid_0's multi_error: 0.0981337\n",
      "Early stopping, best iteration is:\n",
      "[366]\tvalid_0's multi_error: 0.0969296\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087, 0.09211318482841661, 0.08699578567128236, 0.09060806742925948, 0.0851896447922938, 0.09692956050571945]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.0987357\n",
      "[200]\tvalid_0's multi_error: 0.0921132\n",
      "[300]\tvalid_0's multi_error: 0.0906081\n",
      "[400]\tvalid_0's multi_error: 0.0906081\n",
      "Early stopping, best iteration is:\n",
      "[379]\tvalid_0's multi_error: 0.089705\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087, 0.09211318482841661, 0.08699578567128236, 0.09060806742925948, 0.0851896447922938, 0.09692956050571945, 0.0897049969897652]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.103282\n",
      "[200]\tvalid_0's multi_error: 0.0981632\n",
      "[300]\tvalid_0's multi_error: 0.0960554\n",
      "[400]\tvalid_0's multi_error: 0.0960554\n",
      "Early stopping, best iteration is:\n",
      "[346]\tvalid_0's multi_error: 0.0951521\n",
      "[0.09602649006622517, 0.10174593618302227, 0.09723058398555087, 0.09211318482841661, 0.08699578567128236, 0.09060806742925948, 0.0851896447922938, 0.09692956050571945, 0.0897049969897652, 0.09515206263173742]\n",
      "训练模型结束END\n"
     ]
    }
   ],
   "source": [
    "print('开始训练模型BEGIN')\n",
    "lgb_preds, lgb_oof = lgb_model(train = train[feature_names],\n",
    "                               target = train['lable'],\n",
    "                               test = test[feature_names], \n",
    "                               k = 10)\n",
    "print('训练模型结束END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d57da94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取提交格式\n",
    "sub=pd.read_csv('data/submit_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7477efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最大概率标签\n",
    "sub['predict']=np.argmax(lgb_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75e43a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "sub.to_csv('data/sub.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d27ab168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9068304283693067"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 显示分数\n",
    "accuracy_score(train['lable'],np.argmax(lgb_oof,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677caf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
